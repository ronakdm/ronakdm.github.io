---
layout: default
title: 'Research'
---

<h1 style="margin-top:0;">Research</h1>

<p class="lead"><small>
    My research involves developing methods that 1) tackle applied data science problems, 2) are
    statistically principled, and 3) are implemented in user-friendly software packages.
    You can find detailed information including references on <a class="active" href="cv.html">my CV</a>.</small></p>

<h4 style="margin-top:0">Continual/Lifelong Learning</h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
  Continual/lifelong learning can be seen a a generalization of transfer and multitask learning, in which the learning
  algorithm
  trains serially on a sequence of tasks, aiming to increase performance on all tasks by virtue of
  observing the entire sequence. Many current methods suffer from “catastrophic forgetting”, in which algorithms may
  increase
  in performance forward in the sequence, but degrade in performance on previous tasks. Our team proposed a general
  approach to not only combat forgetting, but increase performance on previous tasks, by ensembling data representations
  from multiple tasks to make inferences. We instantiated our generic “<a
    href="https://arxiv.org/abs/2004.12908">ensembling
    representations</a>” approach for both decision
  forests and neural networks, both of which are implemented in the open-source
  <a href="https://proglearn.neurodata.io/">ProgLearn package</a>. Another problem
  relevant to these multitask settings is estimating task similarity, to assess whether
  other tasks are helpful, unhelpful, or adversarial for transfer learning. To this end, we proposed a novel and
  principled measure of <a href="https://arxiv.org/abs/2011.06557">task similarity</a> that encapsulates canonical
  examples of helpful and adversarial tasks.
</p>
<br />

<h4 style="margin-top:0">Decision Forest Theory and Methods</h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
  Decision forests (a.k.a. random forests) are versatile tools for machine learning practitioners, having both
  theoretical connections to classical partition rules, and applied advantages such as interpretability, robustness to
  hyperparameters, and parallelizability. When using honest sampling (using separate data to estimate the decision trees
  and the within-leaf response probabilities), one can achieve calibrated uncertainty estimates in problems such as
  classification. Leveraging this, our team developed <a href="https://arxiv.org/abs/1907.00325">Uncertainty Forests
    (UF)</a>, a decision forest method to
  nonparametrically estimate the conditional entropy and mutual information between random variables. These are
  fundamental information functionals, yet notoriously difficult to estimate. Our method performs well in low and
  high-dimensional settings.
  We also proposed
  <a href="https://arxiv.org/abs/1909.11799">Manifold Oblique Random Forests (MORF)</a>, an extension of random forests
  for structured data such as time series and
  images. MORF leverages local dependence between features to generate partitions of feature space that are more
  informative for tasks such as image classification.
</p>
<br />

<h4 style="margin-top:0">Nonparametric Estimation and Testing</h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
  Independence testing (detecting whether random variables are dependent from samples) and two-sample testing (detecting
  whether random variables are from different distributions from samples) are crucial problems in statistics. Doing
  so nonparametrically is difficult, especially in the case of high-dimensional, structured data. Kernel (or
  equivalently, distance) methods have shown promise for both of these problems. In this line of
  work, I extended multiscale graph correlation (MGC), the state-of-the-art among these methods, to handle time series
  data. The method, dubbed <a href="https://arxiv.org/abs/1908.06486">cross multiscale graph correlation (MGCX)</a>,
  outperforms competitors in detecting nonlinear
  relationships between data, and has immediate applications functional connectomics via fMRI time series. MGCX is
  implemented in <a href="https://arxiv.org/abs/1907.02088">hyppo</a>, a general purpose software package for
  hypothesis testing in Python.
</p>